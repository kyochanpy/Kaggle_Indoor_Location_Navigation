{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9pVZPH/H+cGIbphs/A6xs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyochanpy/Kaggle_Indoor_Location_Navigation/blob/main/note_books/02_indoor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrhlb2cwlsg-",
        "outputId": "7294a11c-caf8-4332-bb8f-3bb94cc84928"
      },
      "source": [
        "!pip install -U kaggle\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "\n",
        "\n",
        "!kaggle datasets download -d hiro5299834/indoor-navigation-and-location-wifi-features\n",
        "!unzip indoor-navigation-and-location-wifi-features.zip -d indoor-navigation-and-location-wifi-features"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 18.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 14.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 10.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=1b58363feade8e590b9c9f80751dfaa7ad213dab26e3efce80ec81f9b974040d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.10\n",
            "    Uninstalling kaggle-1.5.10:\n",
            "      Successfully uninstalled kaggle-1.5.10\n",
            "Successfully installed kaggle-1.5.12\n",
            "Download 100%.\n",
            "Downloading indoor-navigation-and-location-wifi-features.zip to /content\n",
            " 99% 121M/123M [00:01<00:00, 72.1MB/s] \n",
            "100% 123M/123M [00:01<00:00, 87.2MB/s]\n",
            "Archive:  indoor-navigation-and-location-wifi-features.zip\n",
            "  inflating: indoor-navigation-and-location-wifi-features/5a0546857ecc773753327266_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5a0546857ecc773753327266_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5c3c44b80379370013e0fd2b_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5c3c44b80379370013e0fd2b_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27075f03f801723c2e360f_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27075f03f801723c2e360f_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27096c03f801723c31e5e0_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27096c03f801723c31e5e0_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27097f03f801723c320d97_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27097f03f801723c320d97_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27099f03f801723c32511d_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d27099f03f801723c32511d_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709a003f801723c3251bf_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709a003f801723c3251bf_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709b303f801723c327472_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709b303f801723c327472_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709bb03f801723c32852c_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709bb03f801723c32852c_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709c303f801723c3299ee_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709c303f801723c3299ee_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709d403f801723c32bd39_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709d403f801723c32bd39_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709e003f801723c32d896_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5d2709e003f801723c32d896_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138274db8ce0c98bbd3d2_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138274db8ce0c98bbd3d2_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da1382d4db8ce0c98bbe92e_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da1382d4db8ce0c98bbe92e_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138314db8ce0c98bbf3a0_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138314db8ce0c98bbf3a0_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138364db8ce0c98bc00f1_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138364db8ce0c98bc00f1_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da1383b4db8ce0c98bc11ab_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da1383b4db8ce0c98bc11ab_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138754db8ce0c98bca82f_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138754db8ce0c98bca82f_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138764db8ce0c98bcaa46_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138764db8ce0c98bcaa46_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da1389e4db8ce0c98bd0547_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da1389e4db8ce0c98bd0547_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138b74db8ce0c98bd4774_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da138b74db8ce0c98bd4774_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da958dd46f8266d0737457b_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5da958dd46f8266d0737457b_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5dbc1d84c1eb61796cf7c010_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5dbc1d84c1eb61796cf7c010_train.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5dc8cea7659e181adb076a3f_test.csv  \n",
            "  inflating: indoor-navigation-and-location-wifi-features/5dc8cea7659e181adb076a3f_train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiloOaSJmLUS",
        "outputId": "165aa5fb-ba13-455b-c45e-20a2db956025"
      },
      "source": [
        "!git clone --depth 1 https://github.com/location-competition/indoor-location-competition-20 indoor_location_competition_20\n",
        "!rm -rf indoor_location_competition_20/data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'indoor_location_competition_20'...\n",
            "remote: Enumerating objects: 1169, done.\u001b[K\n",
            "remote: Counting objects: 100% (1169/1169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1131/1131), done.\u001b[K\n",
            "remote: Total 1169 (delta 38), reused 1167 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1169/1169), 411.37 MiB | 16.91 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "Checking out files: 100% (1145/1145), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u3Hftj9ou45"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from pathlib import Path\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import lightgbm as lgb\n",
        "\n",
        "import psutil\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "from contextlib import contextmanager\n",
        "\n",
        "\n",
        "import multiprocessing\n",
        "import scipy.interpolate\n",
        "import scipy.sparse\n",
        "\n",
        "from indoor_location_competition_20.io_f import read_data_file\n",
        "import indoor_location_competition_20.compute_f as compute_f"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxXHitLBozf-"
      },
      "source": [
        "@contextmanager\n",
        "def timer(name: str):\n",
        "    t0 = time.time()\n",
        "    p = psutil.Process(os.getpid())\n",
        "    m0 = p.memory_info()[0] / 2. ** 30\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        m1 = p.memory_info()[0] / 2. ** 30\n",
        "        delta = m1 - m0\n",
        "        sign = '+' if delta >= 0 else '-'\n",
        "        delta = math.fabs(delta)\n",
        "        print(f\"[{m1:.1f}GB({sign}{delta:.1f}GB): {time.time() - t0:.3f}sec] {name}\", file=sys.stderr)\n",
        "\n",
        "\n",
        "def set_seed(seed=527):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    \n",
        "def comp_metric(xhat, yhat, fhat, x, y, f):\n",
        "    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n",
        "    return intermediate.sum()/xhat.shape[0]\n",
        "\n",
        "\n",
        "def score_log(df: pd.DataFrame, num_files: int, nam_file: str, data_shape: tuple, n_fold: int, seed: int, mpe: float):\n",
        "    score_dict = {'n_files': num_files, 'file_name': nam_file, 'shape': data_shape, 'fold': n_fold, 'seed': seed, 'score': mpe}\n",
        "    # noinspection PyTypeChecker\n",
        "    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n",
        "    df.to_csv(LOG_PATH / f\"log_score.csv\", index=False)\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4DoCVjzo2MA"
      },
      "source": [
        "N_SPLITS = 5\n",
        "SEED = 618\n",
        "set_seed(SEED)\n",
        "/content/indoor-navigation-and-location-wifi-features"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFWUekodo5JD"
      },
      "source": [
        "LOG_PATH = Path(\"./log/\")\n",
        "LOG_PATH.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYWFRYoLo7XR"
      },
      "source": [
        "feature_dir = \"/content/indoor-navigation-and-location-wifi-features\"\n",
        "train_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\n",
        "test_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\n",
        "subm = pd.read_csv('/content/sample_submission.csv', index_col=0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdtX0Pj8o-HO"
      },
      "source": [
        "lgb_params = {'objective': 'root_mean_squared_error',\n",
        "              'boosting_type': 'gbdt',\n",
        "              'n_estimators': 50000,\n",
        "              'learning_rate': 0.1,\n",
        "              'num_leaves': 90,\n",
        "              'colsample_bytree': 0.4,\n",
        "              'subsample': 0.6,\n",
        "              'subsample_freq': 2,\n",
        "              'bagging_seed': SEED,\n",
        "              'reg_alpha': 8,\n",
        "              'reg_lambda': 2,\n",
        "              'random_state': SEED,\n",
        "              'n_jobs': -1\n",
        "              }\n",
        "\n",
        "lgb_f_params = {'objective': 'multiclass',\n",
        "                'boosting_type': 'gbdt',\n",
        "                'n_estimators': 50000,\n",
        "                'learning_rate': 0.1,\n",
        "                'num_leaves': 90,\n",
        "                'colsample_bytree': 0.4,\n",
        "                'subsample': 0.6,\n",
        "                'subsample_freq': 2,\n",
        "                'bagging_seed': SEED,\n",
        "                'reg_alpha': 10,\n",
        "                'reg_lambda': 2,\n",
        "                'random_state': SEED,\n",
        "                'n_jobs': -1\n",
        "                }"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7TcALCFGpB20",
        "outputId": "f474cc9c-6dc3-4b06-b4b7-f26982816770"
      },
      "source": [
        "score_df = pd.DataFrame()\n",
        "oof = list()\n",
        "predictions = list()\n",
        "for n_files, file in enumerate(train_files):\n",
        "    data = pd.read_csv(file, index_col=0)\n",
        "    test_data = pd.read_csv(test_files[n_files], index_col=0)\n",
        "\n",
        "    oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n",
        "    preds_x, preds_y = 0, 0\n",
        "    preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n",
        "\n",
        "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    for fold, (trn_idx, val_idx) in enumerate(kf.split(data.iloc[:, :-4])):\n",
        "        X_train = data.iloc[trn_idx, :-4]\n",
        "        y_trainx = data.iloc[trn_idx, -4]\n",
        "        y_trainy = data.iloc[trn_idx, -3]\n",
        "        y_trainf = data.iloc[trn_idx, -2]\n",
        "\n",
        "        X_valid = data.iloc[val_idx, :-4]\n",
        "        y_validx = data.iloc[val_idx, -4]\n",
        "        y_validy = data.iloc[val_idx, -3]\n",
        "        y_validf = data.iloc[val_idx, -2]\n",
        "        \n",
        "        modelx = lgb.LGBMRegressor(**lgb_params)\n",
        "        with timer(\"fit X\"):\n",
        "            modelx.fit(X_train, y_trainx,\n",
        "                       eval_set=[(X_valid, y_validx)],\n",
        "                       eval_metric='rmse',\n",
        "                       verbose=False,\n",
        "                       early_stopping_rounds=20\n",
        "                       )\n",
        "\n",
        "        modely = lgb.LGBMRegressor(**lgb_params)\n",
        "        with timer(\"fit Y\"):\n",
        "            modely.fit(X_train, y_trainy,\n",
        "                       eval_set=[(X_valid, y_validy)],\n",
        "                       eval_metric='rmse',\n",
        "                       verbose=False,\n",
        "                       early_stopping_rounds=20\n",
        "                       )\n",
        "            \n",
        "        modelf = lgb.LGBMClassifier(**lgb_f_params)\n",
        "        with timer(\"fit F\"):\n",
        "            modelf.fit(X_train, y_trainf,\n",
        "                       eval_set=[(X_valid, y_validf)],\n",
        "                       eval_metric='multi_logloss',\n",
        "                       verbose=False,\n",
        "                       early_stopping_rounds=20\n",
        "                       )\n",
        "            \n",
        "        oof_x[val_idx] = modelx.predict(X_valid)\n",
        "        oof_y[val_idx] = modely.predict(X_valid)\n",
        "        oof_f[val_idx] = modelf.predict(X_valid).astype(int)\n",
        "\n",
        "        preds_x += modelx.predict(test_data.iloc[:, :-1]) / N_SPLITS\n",
        "        preds_y += modely.predict(test_data.iloc[:, :-1]) / N_SPLITS\n",
        "        preds_f_arr[:, fold] = modelf.predict(test_data.iloc[:, :-1]).astype(int)\n",
        "\n",
        "        score = comp_metric(oof_x[val_idx], oof_y[val_idx], oof_f[val_idx],\n",
        "                            y_validx.to_numpy(), y_validy.to_numpy(), y_validf.to_numpy())\n",
        "        print(f\"fold {fold}: mean position error {score}\")\n",
        "        score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, fold, SEED, score)\n",
        "\n",
        "    print(\"*+\"*40)\n",
        "    print(f\"file #{n_files}, shape={data.shape}, name={os.path.basename(file)}\")\n",
        "    score = comp_metric(oof_x, oof_y, oof_f,\n",
        "                        data.iloc[:, -4].to_numpy(), data.iloc[:, -3].to_numpy(), data.iloc[:, -2].to_numpy())\n",
        "    oof.append(score)\n",
        "    print(f\"mean position error {score}\")\n",
        "    print(\"*+\"*40)\n",
        "    score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, 999, SEED, score)\n",
        "\n",
        "    preds_f_mode = stats.mode(preds_f_arr, axis=1)\n",
        "    preds_f = preds_f_mode[0].astype(int).reshape(-1)\n",
        "    test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n",
        "    test_preds.columns = subm.columns\n",
        "    test_preds.index = test_data[\"site_path_timestamp\"]\n",
        "    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n",
        "    predictions.append(test_preds)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.6GB(+0.2GB): 40.397sec] fit X\n",
            "[1.6GB(+0.0GB): 27.507sec] fit Y\n",
            "[1.6GB(+0.0GB): 22.681sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 3.796929387094887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[1.8GB(+0.2GB): 30.828sec] fit X\n",
            "[1.8GB(+0.0GB): 36.683sec] fit Y\n",
            "[1.8GB(+0.0GB): 14.511sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 3.7084058104886153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(+0.2GB): 35.690sec] fit X\n",
            "[2.0GB(+0.0GB): 24.582sec] fit Y\n",
            "[2.0GB(+0.0GB): 20.160sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 3.67866649657935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(+0.0GB): 28.684sec] fit X\n",
            "[2.0GB(+0.0GB): 27.611sec] fit Y\n",
            "[2.0GB(+0.0GB): 18.039sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 3.8027109909074124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(+0.0GB): 45.569sec] fit X\n",
            "[2.0GB(+0.0GB): 36.269sec] fit Y\n",
            "[2.0GB(+0.0GB): 19.266sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4: mean position error 3.654773421352437\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
            "file #0, shape=(9296, 3401), name=5a0546857ecc773753327266_train.csv\n",
            "mean position error 3.72830460426279\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(+0.0GB): 23.834sec] fit X\n",
            "[2.0GB(+0.0GB): 25.264sec] fit Y\n",
            "[2.0GB(+0.0GB): 26.089sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 4.695191108097891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(+0.0GB): 38.897sec] fit X\n",
            "[2.0GB(+0.0GB): 22.741sec] fit Y\n",
            "[2.0GB(+0.0GB): 25.961sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 4.8243963535899335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(+0.0GB): 34.775sec] fit X\n",
            "[2.0GB(+0.0GB): 30.224sec] fit Y\n",
            "[2.0GB(+0.0GB): 27.963sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 4.727554870661329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(+0.0GB): 30.155sec] fit X\n",
            "[2.0GB(+0.0GB): 24.901sec] fit Y\n",
            "[2.0GB(+0.0GB): 25.301sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 4.677396679419445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[2.0GB(-0.0GB): 32.538sec] fit X\n",
            "[2.0GB(+0.0GB): 34.568sec] fit Y\n",
            "[2.0GB(+0.0GB): 23.582sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4: mean position error 4.585614485994146\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
            "file #1, shape=(9737, 3067), name=5c3c44b80379370013e0fd2b_train.csv\n",
            "mean position error 4.702042564199009\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8.8GB(+1.9GB): 187.515sec] fit X\n",
            "[8.8GB(-0.0GB): 239.144sec] fit Y\n",
            "[7.6GB(-1.2GB): 244.711sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 3.834063898827922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8.5GB(+0.7GB): 246.755sec] fit X\n",
            "[7.0GB(-1.5GB): 226.754sec] fit Y\n",
            "[8.4GB(+1.4GB): 211.212sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 3.853982181633548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[8.7GB(+0.3GB): 204.286sec] fit X\n",
            "[7.0GB(-1.6GB): 226.243sec] fit Y\n",
            "[8.5GB(+1.5GB): 252.170sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 3.7852958502202982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9.5GB(+1.0GB): 261.165sec] fit X\n",
            "[8.4GB(-1.2GB): 274.442sec] fit Y\n",
            "[9.4GB(+1.0GB): 185.773sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 3.8029187845368577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.7GB(-1.7GB): 228.543sec] fit X\n",
            "[9.0GB(+1.3GB): 217.785sec] fit Y\n",
            "[9.0GB(+0.0GB): 186.698sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4: mean position error 3.847196123669304\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
            "file #2, shape=(23666, 7033), name=5d27075f03f801723c2e360f_train.csv\n",
            "mean position error 3.824691763811181\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9.6GB(+0.1GB): 17.474sec] fit X\n",
            "[9.6GB(+0.0GB): 16.295sec] fit Y\n",
            "[9.6GB(+0.0GB): 11.029sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 2.531817743814894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9.6GB(+0.0GB): 12.285sec] fit X\n",
            "[9.6GB(+0.0GB): 11.857sec] fit Y\n",
            "[9.6GB(+0.0GB): 11.293sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 2.540947869173537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[9.6GB(-0.0GB): 13.736sec] fit X\n",
            "[9.6GB(+0.0GB): 12.912sec] fit Y\n",
            "[9.6GB(-0.0GB): 9.782sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 2.604383139893346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.1GB(-2.5GB): 21.140sec] fit X\n",
            "[7.5GB(+0.4GB): 16.010sec] fit Y\n",
            "[7.5GB(-0.0GB): 11.100sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 2.639681274396755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.5GB(+0.0GB): 16.336sec] fit X\n",
            "[7.5GB(+0.0GB): 18.330sec] fit Y\n",
            "[7.5GB(+0.0GB): 12.209sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4: mean position error 2.509531665288294\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
            "file #3, shape=(9100, 4968), name=5d27096c03f801723c31e5e0_train.csv\n",
            "mean position error 2.5652723385133647\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 23.420sec] fit X\n",
            "[7.6GB(+0.0GB): 34.468sec] fit Y\n",
            "[7.6GB(+0.0GB): 21.087sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 4.969307623910416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 25.631sec] fit X\n",
            "[7.6GB(+0.0GB): 31.145sec] fit Y\n",
            "[7.6GB(+0.0GB): 24.947sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 4.640284593423071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 36.264sec] fit X\n",
            "[7.6GB(+0.0GB): 40.129sec] fit Y\n",
            "[7.6GB(+0.0GB): 25.044sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 4.668633751466755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 29.491sec] fit X\n",
            "[7.6GB(+0.0GB): 31.434sec] fit Y\n",
            "[7.6GB(+0.0GB): 24.337sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 4.613417005755175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 26.037sec] fit X\n",
            "[7.6GB(-0.0GB): 29.917sec] fit Y\n",
            "[7.6GB(+0.0GB): 24.942sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4: mean position error 4.602609205171416\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
            "file #4, shape=(10507, 2494), name=5d27097f03f801723c320d97_train.csv\n",
            "mean position error 4.698870602629048\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 2.755sec] fit X\n",
            "[7.6GB(+0.0GB): 2.843sec] fit Y\n",
            "[7.6GB(+0.0GB): 2.457sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 2.7581024707111115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 4.275sec] fit X\n",
            "[7.6GB(+0.0GB): 3.997sec] fit Y\n",
            "[7.6GB(+0.0GB): 2.024sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 2.759960706415104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 3.164sec] fit X\n",
            "[7.6GB(+0.0GB): 2.241sec] fit Y\n",
            "[7.6GB(+0.0GB): 2.678sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 2.7533813404972043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 3.214sec] fit X\n",
            "[7.6GB(+0.0GB): 3.749sec] fit Y\n",
            "[7.6GB(+0.0GB): 2.530sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 2.860129353408569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 3.709sec] fit X\n",
            "[7.6GB(+0.0GB): 3.304sec] fit Y\n",
            "[7.6GB(+0.0GB): 3.076sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4: mean position error 2.781123412634938\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
            "file #5, shape=(4251, 929), name=5d27099f03f801723c32511d_train.csv\n",
            "mean position error 2.7825337082069157\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 4.421sec] fit X\n",
            "[7.6GB(+0.0GB): 3.776sec] fit Y\n",
            "[7.6GB(+0.0GB): 2.739sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 2.8318592357111534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 3.585sec] fit X\n",
            "[7.6GB(+0.0GB): 3.261sec] fit Y\n",
            "[7.6GB(+0.0GB): 2.001sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 3.0282334101119575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[7.6GB(+0.0GB): 4.156sec] fit X\n",
            "[7.6GB(+0.0GB): 4.456sec] fit Y\n",
            "[7.6GB(+0.0GB): 3.279sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 2.8724970035868216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5.6GB(-2.1GB): 10.959sec] fit X\n",
            "[5.6GB(+0.1GB): 4.820sec] fit Y\n",
            "[5.6GB(+0.0GB): 2.332sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 2.8488464056368312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[5.7GB(+0.0GB): 4.267sec] fit X\n",
            "[5.7GB(+0.0GB): 4.298sec] fit Y\n",
            "[5.7GB(+0.0GB): 2.803sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4: mean position error 2.8776560413031493\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n",
            "file #6, shape=(3940, 1256), name=5d2709a003f801723c3251bf_train.csv\n",
            "mean position error 2.8918184192699825\n",
            "*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+*+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6.2GB(+0.1GB): 28.826sec] fit X\n",
            "[6.2GB(+0.0GB): 39.478sec] fit Y\n",
            "[6.2GB(+0.0GB): 31.855sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0: mean position error 3.0707521663033632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6.3GB(+0.0GB): 52.658sec] fit X\n",
            "[6.3GB(+0.0GB): 33.197sec] fit Y\n",
            "[6.3GB(+0.0GB): 37.988sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1: mean position error 3.090834983087904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6.3GB(+0.0GB): 45.313sec] fit X\n",
            "[6.3GB(+0.0GB): 34.623sec] fit Y\n",
            "[6.3GB(+0.0GB): 30.479sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2: mean position error 3.134694559642123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6.3GB(+0.0GB): 39.717sec] fit X\n",
            "[6.3GB(+0.0GB): 35.746sec] fit Y\n",
            "[6.3GB(+0.0GB): 37.219sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3: mean position error 3.0976086478885505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[6.3GB(+0.0GB): 31.198sec] fit X\n",
            "[6.3GB(+0.0GB): 27.530sec] fit Y\n",
            "[6.3GB(+0.0GB): 6.982sec] fit F\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6864bf4f22ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m                        \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi_logloss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                        \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                        )\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    742\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip1qeEF2pOCc"
      },
      "source": [
        "INPUT_PATH = '/content/indoor-location-navigation'\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq4T7nVCpVCP"
      },
      "source": [
        "def compute_rel_positions(acce_datas, ahrs_datas):\n",
        "    step_timestamps, step_indexs, step_acce_max_mins = compute_f.compute_steps(acce_datas)\n",
        "    headings = compute_f.compute_headings(ahrs_datas)\n",
        "    stride_lengths = compute_f.compute_stride_length(step_acce_max_mins)\n",
        "    step_headings = compute_f.compute_step_heading(step_timestamps, headings)\n",
        "    rel_positions = compute_f.compute_rel_positions(stride_lengths, step_headings)\n",
        "    return rel_positions"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25quk2r5pX9l"
      },
      "source": [
        "def correct_path(args):\n",
        "    path, path_df = args\n",
        "    \n",
        "    T_ref  = path_df['timestamp'].values\n",
        "    xy_hat = path_df[['x', 'y']].values\n",
        "    \n",
        "    example = read_data_file(f'{INPUT_PATH}/test/{path}.txt')\n",
        "    rel_positions = compute_rel_positions(example.acce, example.ahrs)\n",
        "    if T_ref[-1] > rel_positions[-1, 0]:\n",
        "        rel_positions = [np.array([[0, 0, 0]]), rel_positions, np.array([[T_ref[-1], 0, 0]])]\n",
        "    \n",
        "    else:\n",
        "        rel_positions = [np.array([[0, 0, 0]]), rel_positions]\n",
        "    rel_positions = np.concatenate(rel_positions)\n",
        "    \n",
        "    T_rel = rel_positions[:, 0]\n",
        "    delta_xy_hat = np.diff(scipy.interpolate.interp1d(T_rel, np.cumsum(rel_positions[:, 1:3], axis=0), axis=0)(T_ref), axis=0)\n",
        "\n",
        "    N = xy_hat.shape[0]\n",
        "    delta_t = np.diff(T_ref)\n",
        "    alpha = (8.1)**(-2) * np.ones(N)\n",
        "    beta  = (0.3 + 0.3 * 1e-3 * delta_t)**(-2)\n",
        "    A = scipy.sparse.spdiags(alpha, [0], N, N)\n",
        "    B = scipy.sparse.spdiags( beta, [0], N-1, N-1)\n",
        "    D = scipy.sparse.spdiags(np.stack([-np.ones(N), np.ones(N)]), [0, 1], N-1, N)\n",
        "\n",
        "    Q = A + (D.T @ B @ D)\n",
        "    c = (A @ xy_hat) + (D.T @ (B @ delta_xy_hat))\n",
        "    xy_star = scipy.sparse.linalg.spsolve(Q, c)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'site_path_timestamp' : path_df['site_path_timestamp'],\n",
        "        'floor' : path_df['floor'],\n",
        "        'x' : xy_star[:, 0],\n",
        "        'y' : xy_star[:, 1],\n",
        "    })"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9ZY524Tpako"
      },
      "source": [
        "all_preds = pd.concat(predictions)\n",
        "all_preds = all_preds.reindex(subm.index)\n",
        "all_preds.to_csv('submission.csv')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "np-TfIZUpdZZ",
        "outputId": "0ad7fec1-ff48-45a9-c6fb-9474dc5e5542"
      },
      "source": [
        "sub = pd.read_csv('submission.csv')\n",
        "tmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\n",
        "sub['site'] = tmp[0]\n",
        "sub['path'] = tmp[1]\n",
        "sub['timestamp'] = tmp[2].astype(float)\n",
        "\n",
        "processes = multiprocessing.cpu_count()\n",
        "with multiprocessing.Pool(processes=processes) as pool:\n",
        "    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n",
        "    dfs = tqdm(dfs)\n",
        "    dfs = list(dfs)\n",
        "sub = pd.concat(dfs).sort_values('site_path_timestamp')\n",
        "sub.to_csv('submission_lgbm_02.csv', index=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"<ipython-input-22-977ff61ec2c5>\", line 7, in correct_path\n    example = read_data_file(f'{INPUT_PATH}/test/{path}.txt')\n  File \"/content/indoor_location_competition_20/io_f.py\", line 32, in read_data_file\n    with open(data_filename, 'r', encoding='utf-8') as file:\nFileNotFoundError: [Errno 2] No such file or directory: '/content/indoor-location-navigation/test/00ff0c9a71cc37a2ebdd0f05.txt'\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0b78acebf48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'site_path_timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission_lgbm_01.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/indoor-location-navigation/test/00ff0c9a71cc37a2ebdd0f05.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoAKm8nYpgh3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}