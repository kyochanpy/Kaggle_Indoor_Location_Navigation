{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled63aifjwergojaero.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "19LC6FpdhwFCxfA0O9yrkdHrkltzpXU2t",
      "authorship_tag": "ABX9TyOFyamvkICezSyaocG9/HgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyochanpy/Kaggle_Indoor_Location_Navigation/blob/main/create_dataset/sensor_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hen312wCkfRp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "from scipy import signal\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwIV4tHXqoS9"
      },
      "source": [
        "# pull out all the buildings actually used in the test set, given current method we don't need the other ones\n",
        "ssubm = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "\n",
        "# only 24 of the total buildings are used in the test set, \n",
        "# this allows us to greatly reduce the intial size of the dataset\n",
        "\n",
        "ssubm_df = ssubm[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
        "used_buildings = sorted(ssubm_df[0].value_counts().index.tolist())\n",
        "\n",
        "# dictionary used to map the floor codes to the values used in the submission file. \n",
        "floor_map = {\"B2\":-2, \"B1\":-1, \"F1\":0, \"F2\": 1, \"F3\":2, \"F4\":3, \"F5\":4, \"F6\":5, \"F7\":6,\"F8\":7, \"F9\":8,\n",
        "             \"1F\":0, \"2F\":1, \"3F\":2, \"4F\":3, \"5F\":4, \"6F\":5, \"7F\":6, \"8F\": 7, \"9F\":8}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2sLKo-Cl-x6"
      },
      "source": [
        "#acc_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpVAbviGmwX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce75aec0-5dc3-4156-babb-22d3ca1348d0"
      },
      "source": [
        "#acc_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "                acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "                acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "                acc_path_timestamp_df_.columns = [f'acc_x_{str(i)}' for i in range(100)]\n",
        "                acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                acc_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/acc_100/x')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlzphoCwmwN2"
      },
      "source": [
        "#acc_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'acc_x_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/acc_100/x')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL8dPxqlmwGB"
      },
      "source": [
        "#acc_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "                acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "                acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "                acc_path_timestamp_df_.columns = [f'acc_y_{str(i)}' for i in range(100)]\n",
        "                acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                acc_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/acc_100/y')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PEHDu1fmv8m"
      },
      "source": [
        "#acc_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'acc_y_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/acc_100/y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXb5Rwxh8MZz",
        "outputId": "7c239e66-78ab-4b70-b0fc-b3693eeca2d9"
      },
      "source": [
        "#acc_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "                acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "                acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "                acc_path_timestamp_df_.columns = [f'acc_z_{str(i)}' for i in range(100)]\n",
        "                acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                acc_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/acc_100/z')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq2rPRkf9hOW"
      },
      "source": [
        "#acc_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'acc_z_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/acc_100/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdI419oBmLGP"
      },
      "source": [
        "#gyro_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74LnBoxrnnkW"
      },
      "source": [
        "#gyro_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    gyro_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        gyro_path_df = gyro_df[gyro_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_df = gyro_path_df[(gyro_path_df['timestamp'] >= timestamp_05_list[n]) & (gyro_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(gyro_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_list = gyro_path_timestamp_df['x'].values\n",
        "                gyro_path_timestamp_list_ = np.interp(np.arange(0, len(gyro_path_timestamp_list), len(gyro_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(gyro_path_timestamp_list)), gyro_path_timestamp_list)\n",
        "                gyro_path_timestamp_df_ = pd.DataFrame(gyro_path_timestamp_list_).T\n",
        "                gyro_path_timestamp_df_.columns = [f'gyro_x_{str(i)}' for i in range(100)]\n",
        "                gyro_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                gyro_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(gyro_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/gyro_100/x')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWlwBfZZnnaR"
      },
      "source": [
        "#gyro_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'gyro_x_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/gyro_100/x')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URsGhyW8nnSU"
      },
      "source": [
        "#gyro_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    gyro_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        gyro_path_df = gyro_df[gyro_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_df = gyro_path_df[(gyro_path_df['timestamp'] >= timestamp_05_list[n]) & (gyro_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(gyro_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_list = gyro_path_timestamp_df['y'].values\n",
        "                gyro_path_timestamp_list_ = np.interp(np.arange(0, len(gyro_path_timestamp_list), len(gyro_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(gyro_path_timestamp_list)), gyro_path_timestamp_list)\n",
        "                gyro_path_timestamp_df_ = pd.DataFrame(gyro_path_timestamp_list_).T\n",
        "                gyro_path_timestamp_df_.columns = [f'gyro_y_{str(i)}' for i in range(100)]\n",
        "                gyro_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                gyro_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(gyro_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/gyro_100/y')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7C6llL2nnF6"
      },
      "source": [
        "#gyro_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'gyro_y_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/gyro_100/y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsvyRR5EUeBA"
      },
      "source": [
        "#gyro_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    gyro_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        gyro_path_df = gyro_df[gyro_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_df = gyro_path_df[(gyro_path_df['timestamp'] >= timestamp_05_list[n]) & (gyro_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(gyro_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_list = gyro_path_timestamp_df['z'].values\n",
        "                gyro_path_timestamp_list_ = np.interp(np.arange(0, len(gyro_path_timestamp_list), len(gyro_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(gyro_path_timestamp_list)), gyro_path_timestamp_list)\n",
        "                gyro_path_timestamp_df_ = pd.DataFrame(gyro_path_timestamp_list_).T\n",
        "                gyro_path_timestamp_df_.columns = [f'gyro_z_{str(i)}' for i in range(100)]\n",
        "                gyro_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                gyro_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(gyro_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/gyro_100/z')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA8WwzwwVqmO"
      },
      "source": [
        "#gyro_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'gyro_z_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/gyro_100/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NDSFNjomWql"
      },
      "source": [
        "#mag_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXLhwaN2pGXC"
      },
      "source": [
        "#mag_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    mag_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        mag_path_df = mag_df[mag_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_df = mag_path_df[(mag_path_df['timestamp'] >= timestamp_05_list[n]) & (mag_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(mag_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_list = mag_path_timestamp_df['x'].values\n",
        "                mag_path_timestamp_list_ = np.interp(np.arange(0, len(mag_path_timestamp_list), len(mag_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(mag_path_timestamp_list)), mag_path_timestamp_list)\n",
        "                mag_path_timestamp_df_ = pd.DataFrame(mag_path_timestamp_list_).T\n",
        "                mag_path_timestamp_df_.columns = [f'mag_x_{str(i)}' for i in range(100)]\n",
        "                mag_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                mag_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(mag_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/mag_100/x')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wRVNlZzpGSx"
      },
      "source": [
        "#mag_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'mag_x_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/mag_100/x')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za6NtCIfpGPT"
      },
      "source": [
        "#mag_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    mag_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        mag_path_df = mag_df[mag_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_df = mag_path_df[(mag_path_df['timestamp'] >= timestamp_05_list[n]) & (mag_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(mag_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_list = mag_path_timestamp_df['y'].values\n",
        "                mag_path_timestamp_list_ = np.interp(np.arange(0, len(mag_path_timestamp_list), len(mag_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(mag_path_timestamp_list)), mag_path_timestamp_list)\n",
        "                mag_path_timestamp_df_ = pd.DataFrame(mag_path_timestamp_list_).T\n",
        "                mag_path_timestamp_df_.columns = [f'mag_y_{str(i)}' for i in range(100)]\n",
        "                mag_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                mag_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(mag_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/mag_100/y')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTnVJb_MpGLo"
      },
      "source": [
        "#mag_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'mag_y_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/mag_100/y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNibwN1gUd8o",
        "outputId": "50453db6-7a4a-4ad6-cfdb-3285e02e2944"
      },
      "source": [
        "#mag_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    mag_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        mag_path_df = mag_df[mag_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_df = mag_path_df[(mag_path_df['timestamp'] >= timestamp_05_list[n]) & (mag_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(mag_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_list = mag_path_timestamp_df['z'].values\n",
        "                mag_path_timestamp_list_ = np.interp(np.arange(0, len(mag_path_timestamp_list), len(mag_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(mag_path_timestamp_list)), mag_path_timestamp_list)\n",
        "                mag_path_timestamp_df_ = pd.DataFrame(mag_path_timestamp_list_).T\n",
        "                mag_path_timestamp_df_.columns = [f'mag_z_{str(i)}' for i in range(100)]\n",
        "                mag_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                mag_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(mag_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/mag_100/z')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7hoXckPVqhm"
      },
      "source": [
        "#mag_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'mag_z_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/mag_100/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjK-HDUemcSa"
      },
      "source": [
        "#rotation_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G56TJ7MVpuUK"
      },
      "source": [
        "#rotation_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    rotation_df = pd.read_csv(f'/content/drive/MyDrive/rotation/{building}_rotation_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        rotation_path_df = rotation_df[rotation_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_df = rotation_path_df[(rotation_path_df['timestamp'] >= timestamp_05_list[n]) & (rotation_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_list = rotation_path_timestamp_df['x'].values\n",
        "                rotation_path_timestamp_list_ = np.interp(np.arange(0, len(rotation_path_timestamp_list), len(rotation_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(rotation_path_timestamp_list)), rotation_path_timestamp_list)\n",
        "                rotation_path_timestamp_df_ = pd.DataFrame(rotation_path_timestamp_list_).T\n",
        "                rotation_path_timestamp_df_.columns = [f'rotation_x_{str(i)}' for i in range(100)]\n",
        "                rotation_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                rotation_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(rotation_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/rotation_100/x')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmVmvlNppuNs"
      },
      "source": [
        "#rotation_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'rotation_x_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/rotation_100/x')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix6qXDktpuEY"
      },
      "source": [
        "#rotation_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    rotation_df = pd.read_csv(f'/content/drive/MyDrive/rotation/{building}_rotation_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        rotation_path_df = rotation_df[rotation_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_df = rotation_path_df[(rotation_path_df['timestamp'] >= timestamp_05_list[n]) & (rotation_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_list = rotation_path_timestamp_df['y'].values\n",
        "                rotation_path_timestamp_list_ = np.interp(np.arange(0, len(rotation_path_timestamp_list), len(rotation_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(rotation_path_timestamp_list)), rotation_path_timestamp_list)\n",
        "                rotation_path_timestamp_df_ = pd.DataFrame(rotation_path_timestamp_list_).T\n",
        "                rotation_path_timestamp_df_.columns = [f'rotation_y_{str(i)}' for i in range(100)]\n",
        "                rotation_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                rotation_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(rotation_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/rotation_100/y')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp_txkOvpt_X"
      },
      "source": [
        "#rotation_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'rotation_y_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/rotation_100/y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsUyAVf0Ud6g"
      },
      "source": [
        "#rotation_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    rotation_df = pd.read_csv(f'/content/drive/MyDrive/rotation/{building}_rotation_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        rotation_path_df = rotation_df[rotation_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_df = rotation_path_df[(rotation_path_df['timestamp'] >= timestamp_05_list[n]) & (rotation_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_list = rotation_path_timestamp_df['z'].values\n",
        "                rotation_path_timestamp_list_ = np.interp(np.arange(0, len(rotation_path_timestamp_list), len(rotation_path_timestamp_list) * 0.0101),\n",
        "                                                    np.arange(0, len(rotation_path_timestamp_list)), rotation_path_timestamp_list)\n",
        "                rotation_path_timestamp_df_ = pd.DataFrame(rotation_path_timestamp_list_).T\n",
        "                rotation_path_timestamp_df_.columns = [f'rotation_z_{str(i)}' for i in range(100)]\n",
        "                rotation_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                rotation_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(rotation_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/rotation_100/z')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPgSqD47Vqe_"
      },
      "source": [
        "#rotation_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0101),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'rotation_z_{str(i)}' for i in range(100)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/rotation_100/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRCMNV-KvJEd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}