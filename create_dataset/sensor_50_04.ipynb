{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled63.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/kyochanpy/Kaggle_Indoor_Location_Navigation/blob/main/create_dataset/sensor_50_03.ipynb",
      "authorship_tag": "ABX9TyMwFNg4b5nIVAyJ/3AGUD66",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyochanpy/Kaggle_Indoor_Location_Navigation/blob/main/create_dataset/sensor_50_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hen312wCkfRp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "from scipy import signal\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwIV4tHXqoS9"
      },
      "source": [
        "# pull out all the buildings actually used in the test set, given current method we don't need the other ones\n",
        "ssubm = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "\n",
        "# only 24 of the total buildings are used in the test set, \n",
        "# this allows us to greatly reduce the intial size of the dataset\n",
        "\n",
        "ssubm_df = ssubm[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
        "used_buildings = sorted(ssubm_df[0].value_counts().index.tolist())\n",
        "\n",
        "# dictionary used to map the floor codes to the values used in the submission file. \n",
        "floor_map = {\"B2\":-2, \"B1\":-1, \"F1\":0, \"F2\": 1, \"F3\":2, \"F4\":3, \"F5\":4, \"F6\":5, \"F7\":6,\"F8\":7, \"F9\":8,\n",
        "             \"1F\":0, \"2F\":1, \"3F\":2, \"4F\":3, \"5F\":4, \"6F\":5, \"7F\":6, \"8F\": 7, \"9F\":8}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2sLKo-Cl-x6"
      },
      "source": [
        "#acc_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpVAbviGmwX4",
        "outputId": "030b6ad5-473e-46bc-aa74-15d6be51ac8e"
      },
      "source": [
        "#acc_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "                acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "                acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "                acc_path_timestamp_df_.columns = [f'acc_x_{str(i)}' for i in range(50)]\n",
        "                acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                acc_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/acc_50/x')\n",
        "    print(building)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlzphoCwmwN2"
      },
      "source": [
        "#acc_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'acc_x_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/acc_50/x')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL8dPxqlmwGB",
        "outputId": "11b1fcac-50e1-4cbf-eafb-1685f2b7b126"
      },
      "source": [
        "#acc_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "                acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "                acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "                acc_path_timestamp_df_.columns = [f'acc_y_{str(i)}' for i in range(50)]\n",
        "                acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                acc_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/acc_50/y')\n",
        "    print(building)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PEHDu1fmv8m"
      },
      "source": [
        "#acc_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'acc_y_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/acc_50/y')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXb5Rwxh8MZz",
        "outputId": "7c239e66-78ab-4b70-b0fc-b3693eeca2d9"
      },
      "source": [
        "#acc_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "                acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "                acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "                acc_path_timestamp_df_.columns = [f'acc_z_{str(i)}' for i in range(50)]\n",
        "                acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                acc_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/acc_50/z')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq2rPRkf9hOW"
      },
      "source": [
        "#acc_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/accelerometer/{building}_accelerometer_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'acc_z_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/acc_50/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdI419oBmLGP"
      },
      "source": [
        "#gyro_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74LnBoxrnnkW",
        "outputId": "ea2587d6-8fdc-489f-eb66-9884314578cd"
      },
      "source": [
        "#gyro_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    gyro_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        gyro_path_df = gyro_df[gyro_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_df = gyro_path_df[(gyro_path_df['timestamp'] >= timestamp_05_list[n]) & (gyro_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(gyro_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_list = gyro_path_timestamp_df['x'].values\n",
        "                gyro_path_timestamp_list_ = np.interp(np.arange(0, len(gyro_path_timestamp_list), len(gyro_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(gyro_path_timestamp_list)), gyro_path_timestamp_list)\n",
        "                gyro_path_timestamp_df_ = pd.DataFrame(gyro_path_timestamp_list_).T\n",
        "                gyro_path_timestamp_df_.columns = [f'gyro_x_{str(i)}' for i in range(50)]\n",
        "                gyro_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                gyro_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(gyro_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/gyro_50/x')\n",
        "    print(building)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWlwBfZZnnaR"
      },
      "source": [
        "#gyro_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'gyro_x_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/gyro_50/x')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URsGhyW8nnSU",
        "outputId": "d8966770-bb93-40b3-b45f-e13401fb13ad"
      },
      "source": [
        "#gyro_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    gyro_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        gyro_path_df = gyro_df[gyro_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_df = gyro_path_df[(gyro_path_df['timestamp'] >= timestamp_05_list[n]) & (gyro_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(gyro_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_list = gyro_path_timestamp_df['y'].values\n",
        "                gyro_path_timestamp_list_ = np.interp(np.arange(0, len(gyro_path_timestamp_list), len(gyro_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(gyro_path_timestamp_list)), gyro_path_timestamp_list)\n",
        "                gyro_path_timestamp_df_ = pd.DataFrame(gyro_path_timestamp_list_).T\n",
        "                gyro_path_timestamp_df_.columns = [f'gyro_y_{str(i)}' for i in range(50)]\n",
        "                gyro_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                gyro_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(gyro_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/gyro_50/y')\n",
        "    print(building)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7C6llL2nnF6"
      },
      "source": [
        "#gyro_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'gyro_y_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/gyro_50/y')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsvyRR5EUeBA"
      },
      "source": [
        "#gyro_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    gyro_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        gyro_path_df = gyro_df[gyro_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_df = gyro_path_df[(gyro_path_df['timestamp'] >= timestamp_05_list[n]) & (gyro_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(gyro_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                gyro_path_timestamp_list = gyro_path_timestamp_df['z'].values\n",
        "                gyro_path_timestamp_list_ = np.interp(np.arange(0, len(gyro_path_timestamp_list), len(gyro_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(gyro_path_timestamp_list)), gyro_path_timestamp_list)\n",
        "                gyro_path_timestamp_df_ = pd.DataFrame(gyro_path_timestamp_list_).T\n",
        "                gyro_path_timestamp_df_.columns = [f'gyro_z_{str(i)}' for i in range(50)]\n",
        "                gyro_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                gyro_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(gyro_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/gyro_50/z')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA8WwzwwVqmO"
      },
      "source": [
        "#gyro_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/gyroscope/{building}_gyroscope_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'gyro_z_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/gyro_50/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NDSFNjomWql"
      },
      "source": [
        "#mag_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXLhwaN2pGXC",
        "outputId": "69ccd510-3a21-4444-ce12-5315cbd60661"
      },
      "source": [
        "#mag_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    mag_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        mag_path_df = mag_df[mag_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_df = mag_path_df[(mag_path_df['timestamp'] >= timestamp_05_list[n]) & (mag_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(mag_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_list = mag_path_timestamp_df['x'].values\n",
        "                mag_path_timestamp_list_ = np.interp(np.arange(0, len(mag_path_timestamp_list), len(mag_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(mag_path_timestamp_list)), mag_path_timestamp_list)\n",
        "                mag_path_timestamp_df_ = pd.DataFrame(mag_path_timestamp_list_).T\n",
        "                mag_path_timestamp_df_.columns = [f'mag_x_{str(i)}' for i in range(50)]\n",
        "                mag_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                mag_path_timestamp_df_['path_id'] = path\n",
        "                dfs_.append(mag_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/mag_50/x')\n",
        "    print(building)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wRVNlZzpGSx"
      },
      "source": [
        "#mag_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'mag_x_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/mag_50/x')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za6NtCIfpGPT",
        "outputId": "7860d0a4-b18b-4ec3-dfed-c02792f777e5"
      },
      "source": [
        "#mag_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    mag_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        mag_path_df = mag_df[mag_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_df = mag_path_df[(mag_path_df['timestamp'] >= timestamp_05_list[n]) & (mag_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(mag_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_list = mag_path_timestamp_df['y'].values\n",
        "                mag_path_timestamp_list_ = np.interp(np.arange(0, len(mag_path_timestamp_list), len(mag_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(mag_path_timestamp_list)), mag_path_timestamp_list)\n",
        "                mag_path_timestamp_df_ = pd.DataFrame(mag_path_timestamp_list_).T\n",
        "                mag_path_timestamp_df_.columns = [f'mag_y_{str(i)}' for i in range(50)]\n",
        "                mag_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                mag_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(mag_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/mag_50/y')\n",
        "    print(building)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTnVJb_MpGLo"
      },
      "source": [
        "#mag_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'mag_y_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/mag_50/y')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNibwN1gUd8o",
        "outputId": "50453db6-7a4a-4ad6-cfdb-3285e02e2944"
      },
      "source": [
        "#mag_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    mag_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        mag_path_df = mag_df[mag_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_df = mag_path_df[(mag_path_df['timestamp'] >= timestamp_05_list[n]) & (mag_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(mag_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                mag_path_timestamp_list = mag_path_timestamp_df['z'].values\n",
        "                mag_path_timestamp_list_ = np.interp(np.arange(0, len(mag_path_timestamp_list), len(mag_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(mag_path_timestamp_list)), mag_path_timestamp_list)\n",
        "                mag_path_timestamp_df_ = pd.DataFrame(mag_path_timestamp_list_).T\n",
        "                mag_path_timestamp_df_.columns = [f'mag_z_{str(i)}' for i in range(50)]\n",
        "                mag_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                mag_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(mag_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/mag_50/z')\n",
        "    print(building)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7hoXckPVqhm"
      },
      "source": [
        "#mag_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/magnetic_field/{building}_magnetic_field_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'mag_z_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/mag_50/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjK-HDUemcSa"
      },
      "source": [
        "#rotation_50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G56TJ7MVpuUK",
        "outputId": "ceb1b609-4f48-47dc-e05c-992c86f008eb"
      },
      "source": [
        "#rotation_x_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    rotation_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        rotation_path_df = rotation_df[rotation_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_df = rotation_path_df[(rotation_path_df['timestamp'] >= timestamp_05_list[n]) & (rotation_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(rotation_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_list = rotation_path_timestamp_df['x'].values\n",
        "                rotation_path_timestamp_list_ = np.interp(np.arange(0, len(rotation_path_timestamp_list), len(rotation_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(rotation_path_timestamp_list)), rotation_path_timestamp_list)\n",
        "                rotation_path_timestamp_df_ = pd.DataFrame(rotation_path_timestamp_list_).T\n",
        "                rotation_path_timestamp_df_.columns = [f'rotation_x_{str(i)}' for i in range(50)]\n",
        "                rotation_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                rotation_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(rotation_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/rotation_50/x')\n",
        "    print(building)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHEtmkMQE31R",
        "outputId": "94e7ce43-e477-4603-b674-d7ef0b3b434f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rotation_path_timestamp_list"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmVmvlNppuNs"
      },
      "source": [
        "#rotation_x_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['x'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['x'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'rotation_x_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/rotation_50/x')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix6qXDktpuEY",
        "outputId": "99edb070-98ac-433c-da55-e232ef24e7c5"
      },
      "source": [
        "#rotation_y_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    rotation_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        rotation_path_df = rotation_df[rotation_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_df = rotation_path_df[(rotation_path_df['timestamp'] >= timestamp_05_list[n]) & (rotation_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(rotation_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_list = rotation_path_timestamp_df['y'].values\n",
        "                rotation_path_timestamp_list_ = np.interp(np.arange(0, len(rotation_path_timestamp_list), len(rotation_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(rotation_path_timestamp_list)), rotation_path_timestamp_list)\n",
        "                rotation_path_timestamp_df_ = pd.DataFrame(rotation_path_timestamp_list_).T\n",
        "                rotation_path_timestamp_df_.columns = [f'rotation_y_{str(i)}' for i in range(50)]\n",
        "                rotation_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                rotation_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(rotation_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/rotation_50/y')\n",
        "    print(building)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5a0546857ecc773753327266\n",
            "5c3c44b80379370013e0fd2b\n",
            "5d27075f03f801723c2e360f\n",
            "5d27096c03f801723c31e5e0\n",
            "5d27097f03f801723c320d97\n",
            "5d27099f03f801723c32511d\n",
            "5d2709a003f801723c3251bf\n",
            "5d2709b303f801723c327472\n",
            "5d2709bb03f801723c32852c\n",
            "5d2709c303f801723c3299ee\n",
            "5d2709d403f801723c32bd39\n",
            "5d2709e003f801723c32d896\n",
            "5da138274db8ce0c98bbd3d2\n",
            "5da1382d4db8ce0c98bbe92e\n",
            "5da138314db8ce0c98bbf3a0\n",
            "5da138364db8ce0c98bc00f1\n",
            "5da1383b4db8ce0c98bc11ab\n",
            "5da138754db8ce0c98bca82f\n",
            "5da138764db8ce0c98bcaa46\n",
            "5da1389e4db8ce0c98bd0547\n",
            "5da138b74db8ce0c98bd4774\n",
            "5da958dd46f8266d0737457b\n",
            "5dbc1d84c1eb61796cf7c010\n",
            "5dc8cea7659e181adb076a3f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp_txkOvpt_X"
      },
      "source": [
        "#rotation_y_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['y'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['y'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'rotation_y_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/rotation_50/y')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsUyAVf0Ud6g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "b7070332-f9a5-4c19-bc1d-42dafcd3f5e4"
      },
      "source": [
        "#rotation_z_train\n",
        "for building in used_buildings:\n",
        "    train_df = pd.read_csv(f'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv')\n",
        "    waypoint_df = pd.read_csv(f'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv')\n",
        "    rotation_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_train.csv')\n",
        "    used_path = sorted(train_df['path'].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        waypoint_path_df = waypoint_df[waypoint_df['path_id'] == path]\n",
        "        rotation_path_df = rotation_df[rotation_df['path_id'] == path]\n",
        "        timestamp_list = list(waypoint_path_df['timestamp'].values)\n",
        "        timestamp_05_list = []\n",
        "        if len(timestamp_list) == 0:\n",
        "            break\n",
        "        else:\n",
        "            timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            else:\n",
        "                timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "                timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_df = rotation_path_df[(rotation_path_df['timestamp'] >= timestamp_05_list[n]) & (rotation_path_df['timestamp'] <= timestamp_05_list[n+1])]\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            else:\n",
        "                rotation_path_timestamp_list = rotation_path_timestamp_df['z'].values\n",
        "                rotation_path_timestamp_list_ = np.interp(np.arange(0, len(rotation_path_timestamp_list), len(rotation_path_timestamp_list) * 0.0201),\n",
        "                                                    np.arange(0, len(rotation_path_timestamp_list)), rotation_path_timestamp_list)\n",
        "                rotation_path_timestamp_df_ = pd.DataFrame(rotation_path_timestamp_list_).T\n",
        "                rotation_path_timestamp_df_.columns = [f'rotation_z_{str(i)}' for i in range(50)]\n",
        "                rotation_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "                rotation_path_timestamp_df_['path'] = path\n",
        "                dfs_.append(rotation_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_train.csv')\n",
        "    shutil.move(f'{building}_train.csv', '/content/drive/MyDrive/rotation_50/z')\n",
        "    print(building)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f72664b5a10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/wifi_train_timestamp_test_path/{building}_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwaypoint_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/waypoint/{building}_waypoint_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrotation_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mused_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \"\"\"\n\u001b[1;32m    532\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPgSqD47Vqe_"
      },
      "source": [
        "#rotation_z_test\n",
        "for building in used_buildings:\n",
        "    test_df = ssubm_df[ssubm_df[0] == building]\n",
        "    acc_df = pd.read_csv(f'/content/drive/MyDrive/rotation_vector/{building}_rotation_vector_test.csv')\n",
        "    used_path = sorted(test_df[1].value_counts().index.tolist())\n",
        "    dfs = []\n",
        "    for path in used_path:\n",
        "        test_path_df = test_df[test_df[1] == path]\n",
        "        acc_path_df = acc_df[acc_df['path_id'] == path]\n",
        "        timestamp_list = list(test_path_df[2].values)\n",
        "        timestamp_list = list(map(int, timestamp_list))\n",
        "        timestamp_05_list = []\n",
        "        timestamp_05_list.append(timestamp_list[0])\n",
        "        dfs_ = []\n",
        "        for n in range(len(timestamp_list)):\n",
        "            if n == len(timestamp_list) - 1:\n",
        "                break\n",
        "            timestamp_05 = int((timestamp_list[n] + timestamp_list[n+1]) * 0.5)\n",
        "            timestamp_05_list.append(timestamp_05)\n",
        "        timestamp_05_list.append(timestamp_list[len(timestamp_list)-1])\n",
        "        for n in range(len(timestamp_05_list)):\n",
        "            if n == len(timestamp_list):\n",
        "                break\n",
        "            acc_path_timestamp_df = acc_path_df[(acc_path_df['timestamp'] >= timestamp_05_list[n]) & (acc_path_df['timestamp'] <= timestamp_05_list[n+1])].fillna(0)\n",
        "            if len(acc_path_timestamp_df['z'].values) == 0:\n",
        "                break\n",
        "            acc_path_timestamp_list = acc_path_timestamp_df['z'].values\n",
        "            acc_path_timestamp_list_ = np.interp(np.arange(0, len(acc_path_timestamp_list), len(acc_path_timestamp_list) * 0.0201),\n",
        "                                                np.arange(0, len(acc_path_timestamp_list)), acc_path_timestamp_list)\n",
        "            acc_path_timestamp_df_ = pd.DataFrame(acc_path_timestamp_list_).T\n",
        "            acc_path_timestamp_df_.columns = [f'rotation_z_{str(i)}' for i in range(50)]\n",
        "            acc_path_timestamp_df_['timestamp'] = timestamp_list[n]\n",
        "            acc_path_timestamp_df_['path'] = path\n",
        "            dfs_.append(acc_path_timestamp_df_)\n",
        "        if len(dfs_) > 0:\n",
        "            df_ = pd.concat(dfs_)\n",
        "        else:\n",
        "            del dfs_\n",
        "        dfs.append(df_)\n",
        "    df = pd.concat(dfs)\n",
        "    df = df[~df.duplicated()]\n",
        "    df.to_csv(f'{building}_test.csv')\n",
        "    shutil.move(f'{building}_test.csv', '/content/drive/MyDrive/rotation_50/z')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C3NK_ZFRG8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}