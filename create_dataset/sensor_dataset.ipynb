{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 54.560577,
      "end_time": "2021-02-02T15:30:17.981511",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-02-02T15:29:23.420934",
      "version": "2.2.2"
    },
    "colab": {
      "name": "feature-store-for-indoor-location-navigation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyochanpy/Kaggle_Indoor_Location_Navigation/blob/main/create_dataset/sensor_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.014566,
          "end_time": "2021-02-02T15:29:29.595620",
          "exception": false,
          "start_time": "2021-02-02T15:29:29.581054",
          "status": "completed"
        },
        "tags": [],
        "id": "gs7t1n_uS3hv"
      },
      "source": [
        "This kernel is introducing feature store for Indoor Location & Navigation competition, because the dataset of this competition is much comlicated and raw data. So it is useful for easy to retrieve data.\n",
        "\n",
        "This script is not finalized. It will be updated for retrieve much more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pun02BKSTASp",
        "outputId": "38fc52a5-bb9e-4be6-e57d-ca7801b48154"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-02-02T15:29:29.647074Z",
          "iopub.status.busy": "2021-02-02T15:29:29.641929Z",
          "iopub.status.idle": "2021-02-02T15:29:30.834228Z",
          "shell.execute_reply": "2021-02-02T15:29:30.834754Z"
        },
        "papermill": {
          "duration": 1.225942,
          "end_time": "2021-02-02T15:29:30.835074",
          "exception": false,
          "start_time": "2021-02-02T15:29:29.609132",
          "status": "completed"
        },
        "tags": [],
        "id": "5FUMxUAuS3iB"
      },
      "source": [
        "import json\n",
        "import re\n",
        "import gc\n",
        "import shutil\n",
        "import pickle\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from datetime import datetime as dt\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "ts_conv = np.vectorize(datetime.datetime.fromtimestamp) # ut(10 digit) -> date\n",
        "\n",
        "# pandas settings -----------------------------------------\n",
        "pd.set_option(\"display.max_colwidth\", 100)\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.options.display.float_format = '{:,.5f}'.format\n",
        "\n",
        "# Graph drawing -------------------------------------------\n",
        "import matplotlib\n",
        "from matplotlib import font_manager\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib import rc\n",
        "from matplotlib_venn import venn2, venn2_circles\n",
        "from matplotlib import animation as ani\n",
        "from IPython.display import Image\n",
        "from pylab import imread\n",
        "\n",
        "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
        "sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\n",
        "red = sns.xkcd_rgb[\"light red\"]\n",
        "green = sns.xkcd_rgb[\"medium green\"]\n",
        "blue = sns.xkcd_rgb[\"denim blue\"]\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "# ML -------------------------------------------\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-02T15:29:30.880649Z",
          "iopub.status.busy": "2021-02-02T15:29:30.875552Z",
          "iopub.status.idle": "2021-02-02T15:29:30.987436Z",
          "shell.execute_reply": "2021-02-02T15:29:30.986761Z"
        },
        "papermill": {
          "duration": 0.135848,
          "end_time": "2021-02-02T15:29:30.987576",
          "exception": false,
          "start_time": "2021-02-02T15:29:30.851728",
          "status": "completed"
        },
        "tags": [],
        "id": "mXtD4RUKS3iD"
      },
      "source": [
        "def unpickle(filename):\n",
        "    with open(filename, 'rb') as fo:\n",
        "        p = pickle.load(fo)\n",
        "    return p\n",
        "\n",
        "def to_pickle(filename, obj):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(obj, f, -1)\n",
        "\n",
        "\n",
        "\n",
        "class FeatureStore():\n",
        "    \n",
        "    # necessayr to re-check\n",
        "    floor_convert = {'1F' :  0, '2F' : 1, '3F' : 2, '4F' : 3, '5F' : 4, \n",
        "                     '6F' : 5, '7F' : 6, '8F' : 7, '9F' : 8,\n",
        "                     'B'  : -1, 'B1' : -1, 'B2' : -2, 'B3' : -3, \n",
        "                     'BF' : -1, 'BM' : -1, \n",
        "                     'F1' : 0, 'F2' : 1, 'F3' : 2, 'F4' : 3, 'F5' : 4, \n",
        "                     'F6' : 5, 'F7' : 6, 'F8' : 7, 'F9' : 8, 'F10': 9,\n",
        "                     'L1' : 0, 'L2' : 1, 'L3' : 2, 'L4' : 3, 'L5' : 4, \n",
        "                     'L6' : 5, 'L7' : 6, 'L8' : 7, 'L9' : 8, 'L10': 9, \n",
        "                     'L11': 10,\n",
        "                     'G'  : 0, 'LG1': 0, 'LG2': 1, 'LM' : 0, 'M'  : 0, \n",
        "                     'P1' : 0, 'P2' : 1,}\n",
        "    \n",
        "    df_types = ['accelerometer',\n",
        "                'accelerometer_uncalibrated',\n",
        "                'beacon',\n",
        "                'gyroscope',\n",
        "                'gyroscope_uncalibrated',\n",
        "                'magnetic_field',\n",
        "                'magnetic_field_uncalibrated',\n",
        "                'rotation_vector',\n",
        "                'waypoint',\n",
        "                'wifi']\n",
        "    \n",
        "    # https://github.com/location-competition/indoor-location-competition-20\n",
        "    df_type_cols = {'accelerometer': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n",
        "                'accelerometer_uncalibrated': [\"timestamp\", \"x\", \"y\", \"z\", \n",
        "                                               \"x2\", \"y2\", \"z2\", \"accuracy\" ],\n",
        "                'beacon': [\"timestamp\", \"uuid\", \"major_id\", \"minor_id\", \"tx_power\", \n",
        "                           \"rssi\", \"distance\", \"mac_addr\", \"timestamp2\"],\n",
        "                'gyroscope': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n",
        "                'gyroscope_uncalibrated': [\"timestamp\", \"x\", \"y\", \"z\", \n",
        "                                           \"x2\", \"y2\", \"z2\", \"accuracy\" ],\n",
        "                'magnetic_field': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n",
        "                'magnetic_field_uncalibrated': [\"timestamp\", \"x\", \"y\", \"z\", \n",
        "                                                \"x2\", \"y2\", \"z2\", \"accuracy\" ],\n",
        "                'rotation_vector': [\"timestamp\", \"x\", \"y\", \"z\", \"accuracy\"],\n",
        "                'waypoint': [\"timestamp\", \"x\", \"y\"],\n",
        "                'wifi': [\"timestamp\", \"ssid\", \"bssid\",\"rssi\",\"frequency\",\n",
        "                         \"last_seen_timestamp\",]}\n",
        "\n",
        "    dtype_dict = {}\n",
        "    dtype_dict[\"accelerometer\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \"z\":float, \n",
        "                                   \"accuracy\":int}\n",
        "    dtype_dict[\"accelerometer_uncalibrated\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n",
        "                                                \"z\":float, \"x2\":float, \"y2\":float, \n",
        "                                                \"z2\":float, \"accuracy\":int}\n",
        "    dtype_dict[\"beacon\"] = {\"timestamp\":int, \"uuid\":str, \"major_id\":str, \n",
        "                            \"minor_id\":str, \"tx_power\":int,  \"rssi\":int, \n",
        "                            \"distance\":float, \"mac_addr\":str, \"timestamp2\":int}\n",
        "    dtype_dict[\"gyroscope\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \"z\":float, \n",
        "                               \"accuracy\":int}\n",
        "    dtype_dict[\"gyroscope_uncalibrated\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n",
        "                                            \"z\":float, \"x2\":float, \"y2\":float, \n",
        "                                            \"z2\":float, \"accuracy\":int}\n",
        "    dtype_dict[\"magnetic_field\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n",
        "                                    \"z\":float, \"accuracy\":int}\n",
        "    dtype_dict[\"magnetic_field_uncalibrated\"] = {\"timestamp\":int, \"x\":float, \n",
        "                                                 \"y\":float, \"z\":float, \"x2\":float, \n",
        "                                                 \"y2\":float, \"z2\":float, \"accuracy\":int}\n",
        "    dtype_dict[\"rotation_vector\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \n",
        "                                     \"z\":float, \"accuracy\":int}\n",
        "    dtype_dict[\"waypoint\"] = {\"timestamp\":int, \"x\":float, \"y\":float, \"z\":float}\n",
        "    dtype_dict[\"wifi\"] = {\"timestamp\":int, \"ssid\":str, \"bssid\":str,\n",
        "                          \"rssi\":int,\"frequency\":int, \"last_seen_timestamp\":int}\n",
        "\n",
        "    def __init__(self, site_id, floor, path_id, \n",
        "                 input_path=\"/content/drive/MyDrive/fixed_train/\",\n",
        "                 save_path=\"../mid\"):\n",
        "        self.site_id = site_id.strip()\n",
        "        self.floor = floor.strip()\n",
        "        self.n_floor = self.floor_convert[self.floor]\n",
        "        self.path_id = path_id.strip()\n",
        "        \n",
        "        self.input_path = input_path\n",
        "        assert Path(input_path).exists(), f\"input_path do not exist: {input_path}\"\n",
        "        \n",
        "        self.save_path = save_path\n",
        "        Path(save_path).mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        self.site_info = SiteInfo(site_id=self.site_id, floor=self.floor, input_path=self.input_path)\n",
        "        \n",
        "    def _flatten(self, l):\n",
        "        return list(itertools.chain.from_iterable(l))\n",
        "    \n",
        "    def multi_line_spliter(self, s):\n",
        "        matches = re.finditer(\"TYPE_\", s)\n",
        "        matches_positions = [match.start() for match in matches]\n",
        "        split_idx = [0] + [matches_positions[i]-14 for i in range(1, len(matches_positions))] + [len(s)]\n",
        "        return [s[split_idx[i]:split_idx[i+1]] for i in range(len(split_idx)-1)]\n",
        "    \n",
        "    def load_df(self, ):\n",
        "        path = str(Path(self.input_path)/f\"train/{self.site_id}/{self.floor}/{self.path_id}.txt\")\n",
        "        with open(path) as f:\n",
        "            data = f.readlines()\n",
        "        \n",
        "        modified_data = []\n",
        "        for s in data:\n",
        "            if s.count(\"TYPE_\")>1:\n",
        "                lines = self.multi_line_spliter(s)\n",
        "                modified_data.extend(lines)\n",
        "            else:\n",
        "                modified_data.append(s)\n",
        "        del data\n",
        "        self.meta_info_len = len([d for d in modified_data if d[0]==\"#\"])\n",
        "        self.meta_info_df = pd.DataFrame([m.replace(\"\\n\", \"\").split(\":\") \n",
        "                                          for m in self._flatten([d.split(\"\\t\") \n",
        "                                                                  for d in modified_data if d[0]==\"#\"]) if m!=\"#\"])\n",
        "\n",
        "        data_df = pd.DataFrame([d.replace(\"\\n\", \"\").split(\"\\t\") for d in modified_data if d[0]!=\"#\"])\n",
        "        for dt in self.df_types:\n",
        "            # select data type\n",
        "            df_s = data_df[data_df[1]==f\"TYPE_{dt.upper()}\"]\n",
        "            if len(df_s)==0:\n",
        "                setattr(self, dt, pd.DataFrame(columns=self.df_type_cols[dt]))\n",
        "            else:\n",
        "                # remove empty cols\n",
        "                na_info = df_s.isna().sum(axis=0) == len(df_s)\n",
        "                df_s = df_s[[i for i in na_info[na_info==False].index if i!=1]].reset_index(drop=True)\n",
        "                \n",
        "                if len(df_s.columns)!=len(self.df_type_cols[dt]):\n",
        "                    df_s.columns = self.df_type_cols[dt][:len(df_s.columns)]\n",
        "                else:\n",
        "                    df_s.columns = self.df_type_cols[dt]\n",
        "            \n",
        "                # set dtype          \n",
        "                for c in df_s.columns:\n",
        "                    df_s[c] = df_s[c].astype(self.dtype_dict[dt][c])\n",
        "                                     \n",
        "                # set DataFrame to attr\n",
        "                setattr(self, dt, df_s)\n",
        "    \n",
        "    def get_site_info(self, keep_raw=False):\n",
        "        self.site_info.get_site_info(keep_raw=keep_raw)\n",
        "            \n",
        "    def load_all_data(self, keep_raw=False):     \n",
        "        self.load_df()\n",
        "        \n",
        "    def __getitem__(self, item):\n",
        "        if item in self.df_types:\n",
        "            return getattr(self, item)\n",
        "        else:\n",
        "            return None\n",
        "    \n",
        "    def save(self, ):\n",
        "        # to be implemented\n",
        "        pass\n",
        "    \n",
        "    \n",
        "class SiteInfo():\n",
        "    def __init__(self, site_id, floor, input_path=\"/content/drive/MyDrive/fixed_train/\"):\n",
        "        self.site_id = site_id\n",
        "        self.floor = floor\n",
        "        self.input_path = input_path\n",
        "        assert Path(input_path).exists(), f\"input_path do not exist: {input_path}\"\n",
        "        \n",
        "    def get_site_info(self, keep_raw=False):\n",
        "        floor_info_path = f\"{self.input_path}/metadata/{self.site_id}/{self.floor}/floor_info.json\"\n",
        "        with open(floor_info_path, \"r\") as f:\n",
        "            self.floor_info = json.loads(f.read())\n",
        "            self.site_height = self.floor_info[\"map_info\"][\"height\"]\n",
        "            self.site_width = self.floor_info[\"map_info\"][\"width\"]\n",
        "            if not keep_raw:\n",
        "                del self.floor_info\n",
        "            \n",
        "        geojson_map_path = f\"{self.input_path}/metadata/{self.site_id}/{self.floor}/geojson_map.json\"\n",
        "        with open(geojson_map_path, \"r\") as f:\n",
        "            self.geojson_map = json.loads(f.read())\n",
        "            self.map_type = self.geojson_map[\"type\"]\n",
        "            self.features = self.geojson_map[\"features\"]\n",
        "            \n",
        "            self.floor_coordinates = self.features[0][\"geometry\"][\"coordinates\"]\n",
        "            self.store_coordinates = [self.features[i][\"geometry\"][\"coordinates\"] \n",
        "                                          for i in range(1, len(self.features))]\n",
        "                \n",
        "            if not keep_raw:\n",
        "                del self.geojson_map\n",
        "    \n",
        "    def show_site_image(self):\n",
        "        path = f\"{self.input_path}/metadata/{self.site_id}/{self.floor}/floor_image.png\"\n",
        "        plt.imshow(imread(path), extent=[0, self.site_width, 0, self.site_height])\n",
        "\n",
        "    def draw_polygon(self, size=8, only_floor=False):\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax = plt.subplot(111)\n",
        "            \n",
        "        xmax, xmin, ymax, ymin = self._draw(self.floor_coordinates, ax, calc_minmax=True)\n",
        "        if not only_floor:\n",
        "            self._draw(self.store_coordinates, ax, fill=True)\n",
        "        plt.legend([])\n",
        "        \n",
        "        xrange = xmax - xmin\n",
        "        yrange = ymax - ymin\n",
        "        ratio = yrange / xrange\n",
        "        \n",
        "        self.x_size = size\n",
        "        self.y_size = size*ratio\n",
        "\n",
        "        fig.set_figwidth(size)\n",
        "        fig.set_figheight(size*ratio)\n",
        "        # plt.show()\n",
        "        return ax\n",
        "        \n",
        "    def _draw(self, coordinates, ax, fill=False, calc_minmax=False):\n",
        "        xmax, ymax = -np.inf, -np.inf\n",
        "        xmin, ymin = np.inf, np.inf\n",
        "        for i in range(len(coordinates)):\n",
        "            ndim = np.ndim(coordinates[i])\n",
        "            if ndim==2:\n",
        "                corrd_df = pd.DataFrame(coordinates[i])\n",
        "                if fill:\n",
        "                    ax.fill(corrd_df[0], corrd_df[1], alpha=0.7)\n",
        "                else:\n",
        "                    corrd_df.plot.line(x=0, y=1, style=\"-\", ax=ax)\n",
        "                        \n",
        "                if calc_minmax:\n",
        "                    xmax = max(xmax, corrd_df[0].max())\n",
        "                    xmin = min(xmin, corrd_df[0].min())\n",
        "\n",
        "                    ymax = max(ymax, corrd_df[1].max())\n",
        "                    ymin = min(ymin, corrd_df[1].min())\n",
        "            elif ndim==3:\n",
        "                for j in range(len(coordinates[i])):\n",
        "                    corrd_df = pd.DataFrame(coordinates[i][j])\n",
        "                    if fill:\n",
        "                        ax.fill(corrd_df[0], corrd_df[1], alpha=0.6)\n",
        "                    else:\n",
        "                        corrd_df.plot.line(x=0, y=1, style=\"-\", ax=ax)\n",
        "                        \n",
        "                    if calc_minmax:\n",
        "                        xmax = max(xmax, corrd_df[0].max())\n",
        "                        xmin = min(xmin, corrd_df[0].min())\n",
        "\n",
        "                        ymax = max(ymax, corrd_df[1].max())\n",
        "                        ymin = min(ymin, corrd_df[1].min())\n",
        "            else:\n",
        "                assert False, f\"ndim of coordinates should be 2 or 3: {ndim}\"\n",
        "        if calc_minmax:\n",
        "            return xmax, xmin, ymax, ymin\n",
        "        else:\n",
        "            return None\n",
        "        "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-02T15:29:31.561059Z",
          "iopub.status.busy": "2021-02-02T15:29:31.560454Z",
          "iopub.status.idle": "2021-02-02T15:29:35.110577Z",
          "shell.execute_reply": "2021-02-02T15:29:35.109937Z"
        },
        "papermill": {
          "duration": 3.569913,
          "end_time": "2021-02-02T15:29:35.110708",
          "exception": false,
          "start_time": "2021-02-02T15:29:31.540795",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TX-7BX6DS3iQ",
        "outputId": "450d3602-05d6-4792-8cec-868c9e39daa4"
      },
      "source": [
        "# train_meta_data\n",
        "train_meta = glob(\"/content/drive/MyDrive/use_data/train/*/*/*\")\n",
        "train_meta_org = pd.DataFrame(train_meta)\n",
        "train_meta = train_meta_org[0].str.split(\"/\", expand=True)[[6, 7, 8]]\n",
        "train_meta.columns = [\"site_id\", \"floor\", \"path_id\"]\n",
        "train_meta[\"path_id\"] = train_meta[\"path_id\"].str.replace(\".txt\", \"\")\n",
        "train_meta[\"path\"] = train_meta_org[0]\n",
        "train_meta.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>floor</th>\n",
              "      <th>path_id</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5a0546857ecc773753327266</td>\n",
              "      <td>B1</td>\n",
              "      <td>5e1573141506f2000638fc31</td>\n",
              "      <td>/content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e1573141506f2000638fc31.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5a0546857ecc773753327266</td>\n",
              "      <td>B1</td>\n",
              "      <td>5e158ef11506f2000638fd1b</td>\n",
              "      <td>/content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e158ef11506f2000638fd1b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5a0546857ecc773753327266</td>\n",
              "      <td>B1</td>\n",
              "      <td>5e1580c51506f2000638fc6a</td>\n",
              "      <td>/content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e1580c51506f2000638fc6a.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5a0546857ecc773753327266</td>\n",
              "      <td>B1</td>\n",
              "      <td>5e158f1f1506f2000638fd3b</td>\n",
              "      <td>/content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e158f1f1506f2000638fd3b.txt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5a0546857ecc773753327266</td>\n",
              "      <td>B1</td>\n",
              "      <td>5e15730e1506f2000638fc2b</td>\n",
              "      <td>/content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e15730e1506f2000638fc2b.txt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    site_id floor                   path_id  \\\n",
              "0  5a0546857ecc773753327266    B1  5e1573141506f2000638fc31   \n",
              "1  5a0546857ecc773753327266    B1  5e158ef11506f2000638fd1b   \n",
              "2  5a0546857ecc773753327266    B1  5e1580c51506f2000638fc6a   \n",
              "3  5a0546857ecc773753327266    B1  5e158f1f1506f2000638fd3b   \n",
              "4  5a0546857ecc773753327266    B1  5e15730e1506f2000638fc2b   \n",
              "\n",
              "                                                                                             path  \n",
              "0  /content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e1573141506f2000638fc31.txt  \n",
              "1  /content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e158ef11506f2000638fd1b.txt  \n",
              "2  /content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e1580c51506f2000638fc6a.txt  \n",
              "3  /content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e158f1f1506f2000638fd3b.txt  \n",
              "4  /content/drive/MyDrive/use_data/train/5a0546857ecc773753327266/B1/5e15730e1506f2000638fc2b.txt  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.016609,
          "end_time": "2021-02-02T15:29:35.143484",
          "exception": false,
          "start_time": "2021-02-02T15:29:35.126875",
          "status": "completed"
        },
        "tags": [],
        "id": "k2kbJeYHS3iQ"
      },
      "source": [
        "# train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y7atRKgTwRl"
      },
      "source": [
        "ssubm = pd.read_csv('/content/drive/MyDrive/sample_submission.csv')\n",
        "\n",
        "# only 24 of the total buildings are used in the test set, \n",
        "# this allows us to greatly reduce the intial size of the dataset\n",
        "\n",
        "ssubm_df = ssubm[\"site_path_timestamp\"].apply(lambda x: pd.Series(x.split(\"_\")))\n",
        "used_buildings = sorted(ssubm_df[0].value_counts().index.tolist())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EGQ5IwpTvyd"
      },
      "source": [
        "for building in used_buildings:\n",
        "    head_index = train_meta.groupby('site_id').get_group(building).head(1).index[0]\n",
        "    tail_index = train_meta.groupby('site_id').get_group(building).tail(1).index[0]\n",
        "    dfs = []\n",
        "    for n in range(head_index,tail_index):\n",
        "        t = train_meta.iloc[n]\n",
        "        feature = FeatureStore(site_id=t.site_id, floor=t.floor, path_id=t.path_id)\n",
        "        feature.load_all_data()\n",
        "        df = feature['gyroscope']\n",
        "        dfs.append(df)\n",
        "    building_df = pd.concat(dfs)\n",
        "    building_df.to_csv(building+\"_gyroscope_train.csv\")\n",
        "    shutil.move(f'/content/{building}_gyroscope_train.csv', '/content/drive/MyDrive/gyroscope')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzy6GVkiUVdv"
      },
      "source": [
        "for building in used_buildings:\n",
        "    head_index = train_meta.groupby('site_id').get_group(building).head(1).index[0]\n",
        "    tail_index = train_meta.groupby('site_id').get_group(building).tail(1).index[0]\n",
        "    dfs = []\n",
        "    for n in range(head_index,tail_index):\n",
        "        t = train_meta.iloc[n]\n",
        "        feature = FeatureStore(site_id=t.site_id, floor=t.floor, path_id=t.path_id)\n",
        "        feature.load_all_data()\n",
        "        df = feature['gyroscope_uncalibrated']\n",
        "        dfs.append(df)\n",
        "    building_df = pd.concat(dfs)\n",
        "    building_df.to_csv(building+\"_gyroscope_uncalibrated_train.csv\")\n",
        "    shutil.move(f'/content/{building}_gyroscope_uncalibrated_train.csv', '/content/drive/MyDrive/gyroscope_uncalibrated')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNq_jpi0UZ8s"
      },
      "source": [
        "for building in used_buildings:\n",
        "    head_index = train_meta.groupby('site_id').get_group(building).head(1).index[0]\n",
        "    tail_index = train_meta.groupby('site_id').get_group(building).tail(1).index[0]\n",
        "    dfs = []\n",
        "    for n in range(head_index,tail_index):\n",
        "        t = train_meta.iloc[n]\n",
        "        feature = FeatureStore(site_id=t.site_id, floor=t.floor, path_id=t.path_id)\n",
        "        feature.load_all_data()\n",
        "        df = feature['magnetic_field']\n",
        "        dfs.append(df)\n",
        "    building_df = pd.concat(dfs)\n",
        "    building_df.to_csv(building+\"_magnetic_field_train.csv\")\n",
        "    shutil.move(f'/content/{building}_magnetic_field_train.csv', '/content/drive/MyDrive/magnetic_field')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0hDT9iKUlFC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}